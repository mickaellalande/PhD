{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMDZORnudge-STD-R01-opti\n",
    "\n",
    "conda env: new `phd_v3` (in `envs/phd`)\n",
    "\n",
    "## LMDZORnudge-STD-NY07\n",
    "\n",
    "- Jean-Zay WORK: `/gpfsdswork/projects/rech/goe/ufz23bm/SCA_parameterization/modipsl/config/LMDZOR_v6/LMDZORnudge-STD-NY07`\n",
    "- Jean-Zay STORE: `/gpfsstore/rech/goe/ufz23bm/IGCM_OUT/LMDZOR/DEVT/amip/LMDZORnudge-STD-NY07`\n",
    "- THREDDS: `/gpfsdsmnt/ipsl/dods/pub/ufz23bm/LMDZOR/DEVT/amip/LMDZORnudge-STD-NY07`\n",
    "- CICLAD: `/thredds/idris/work/ufz23bm/LMDZOR/DEVT/amip/LMDZORnudge-STD-NY07` \n",
    "- https://vesg.ipsl.upmc.fr/thredds/catalog/idris_work/ufz23bm/LMDZOR/DEVT/amip/LMDZORnudge-STD-NY07/catalog.html\n",
    "\n",
    "\n",
    "## LMDZORnudge-STD-R01-opti\n",
    "\n",
    "- Jean-Zay WORK: `/gpfswork/rech/goe/ufz23bm/SCA_parameterization/modipsl/config/LMDZOR_v6/LMDZORnudge-STD-R01-opti`\n",
    "- Jean-Zay STORE: `/gpfsscratch/rech/goe/ufz23bm/IGCM_OUT/LMDZOR/PRDEVTD/amip/LMDZORnudge-STD-R01-opti`\n",
    "- THREDDS: `/gpfsdsmnt/ipsl/dods/pub/ufz23bm/LMDZOR/DEVT/amip/LMDZORnudge-STD-R01-opti`\n",
    "- CICLAD: `/thredds/idris/work/ufz23bm/LMDZOR/DEVT/amip/LMDZORnudge-STD-R01-opti` \n",
    "- https://vesg.ipsl.upmc.fr/thredds/catalog/idris_work/ufz23bm/LMDZOR/DEVT/amip/LMDZORnudge-STD-R01-opti/catalog.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5 | packaged by conda-forge | (default, Jul 24 2020, 01:25:15) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "# To reload external files automatically (ex: utils)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import proplot as plot # New plot library (https://proplot.readthedocs.io/en/latest/)\n",
    "plot.rc['savefig.dpi'] = 300 # 1200 is too big! #https://proplot.readthedocs.io/en/latest/basics.html#Creating-figures\n",
    "from scipy import stats\n",
    "import xesmf as xe # For regridding (https://xesmf.readthedocs.io/en/latest/)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/home/mlalande/notebooks/utils') # to include my util file in previous directory\n",
    "import utils as u # my personal functions\n",
    "u.check_python_version()\n",
    "# u.check_virtual_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/thredds/idris/work/ufz23bm/LMDZOR/DEVT/amip/'\n",
    "exp_ref = 'LMDZORnudge-STD-NY07'\n",
    "exp_new = 'LMDZORnudge-STD-R01-opti'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /thredds/idris/work/ufz23bm/IGCM_OUT/LMDZOR/PROD/clim/LMDZOR-STD-REF/ATM/Analyse/TS_MO/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make function to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(list_vars, period, season, zone):\n",
    "    \"\"\"\n",
    "        Get reference and new experiments + observations.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        list_vars : list\n",
    "            List of variables. Options are: 'frac_snow', 't2m', 'precip', 'ta'\n",
    "        period : slice\n",
    "            Period\n",
    "        season : str\n",
    "            Season (ex: 'annual', 'DJF', '1')\n",
    "        zone : str\n",
    "            Zone of study (ex: 'HMA', 'GLOB', 'NH')\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ref, new, obs : list of Dataset\n",
    "            List of reference and new experiments + observations regrided on model dataset (not \n",
    "            loaded) for each variable.\n",
    "            \n",
    "        clim_ref, clim_new, clim_obs : list of DataArray\n",
    "            List of reference and new experiments + observations regrided on model climatologies\n",
    "            for each variable.\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        >>>  list_ref, list_new, list_obs, list_clim_ref, list_clim_new, list_clim_obs = get_data(\n",
    "                ['frac_snow', 't2m', 'precip'], slice('1981','1989'), 'annual', 'GLOB'\n",
    "            )\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    list_ref = []\n",
    "    list_new = []\n",
    "    list_obs = []\n",
    "    list_clim_ref = []\n",
    "    list_clim_new = []\n",
    "    list_clim_obs = []\n",
    "       \n",
    "    list_var_SRF = ['frac_snow']\n",
    "    list_var_ATM = ['t2m', 'precip', 'ta']\n",
    "    latlim, lonlim = u.get_zone(zone)\n",
    "\n",
    "    for var in list_vars:\n",
    "\n",
    "        print(\n",
    "            f\"\"\"\n",
    "    #############\n",
    "    ### Variable: {var} \n",
    "    #############\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        if var in list_var_SRF:\n",
    "            component = 'SRF'\n",
    "        elif var in list_var_ATM:\n",
    "            component = 'ATM'\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid var argument: '{var}'. Valid names are: 'frac_snow'.\")\n",
    "\n",
    "        path = root+exp_ref+'/'+component+'/Analyse/TS_MO/'+exp_ref+'_20040101_20131231_1M_'+var+'.nc'\n",
    "        print('Open reference simulation:\\n'+path+'\\n')\n",
    "        ref = xr.open_dataset(path)[var]\n",
    "        ref.attrs['title'] = exp_ref\n",
    "\n",
    "        path = root+exp_new+'/'+component+'/Analyse/TS_MO/'+exp_new+'_20040101_20131231_1M_'+var+'.nc'\n",
    "        print('Open new simulation:\\n'+path+'\\n')\n",
    "        new = xr.open_dataset(path)[var]\n",
    "        new.attrs['title'] = exp_new\n",
    "\n",
    "        # Rename time dimension and sort latitude from -90 to 90\n",
    "        ref = ref.rename({'time_counter': 'time'}).sortby('lat')\n",
    "        new = new.rename({'time_counter': 'time'}).sortby('lat')\n",
    "\n",
    "        # Compute climatolgy\n",
    "        clim_ref = u.clim(\n",
    "            ref.sel(time=period, lat=latlim, lon=lonlim), season=season, calendar='standard')\n",
    "        clim_ref.attrs['season'] = season\n",
    "        clim_ref.attrs['zone'] = zone\n",
    "\n",
    "        clim_new = u.clim(\n",
    "            new.sel(time=period, lat=latlim, lon=lonlim), season=season, calendar='standard')\n",
    "        clim_new.attrs['season'] = season\n",
    "        clim_new.attrs['zone'] = zone\n",
    "\n",
    "        # Unit conversion\n",
    "        if var in ['tas', 'tmp', 't2m', 'ta']:\n",
    "            with xr.set_options(keep_attrs=True):\n",
    "                clim_ref -= 273.15\n",
    "                clim_new -= 273.15\n",
    "            clim_ref.attrs['units'] = '°C'\n",
    "            clim_new.attrs['units'] = '°C'\n",
    "\n",
    "            if var in ['ta']:\n",
    "                clim_ref = clim_ref.assign_coords({'plev': clim_ref.plev/100}).rename({'plev': 'level'})\n",
    "                clim_new = clim_new .assign_coords({'plev': clim_new.plev/100}).rename({'plev': 'level'})\n",
    "\n",
    "        elif var in ['pr', 'precip']:\n",
    "            with xr.set_options(keep_attrs=True):\n",
    "                clim_ref *= 86400\n",
    "                clim_new *= 86400\n",
    "            clim_ref.attrs['units'] = 'mm/day'\n",
    "            clim_new.attrs['units'] = 'mm/day'\n",
    "\n",
    "        # Get observations\n",
    "        if var in ['snc', 'frac_snow']:\n",
    "            obs_name = 'NH_SCE_CDR'\n",
    "            version = 'v01r01'\n",
    "        elif var in ['tas', 'tmp', 't2m']:\n",
    "            obs_name = 'CRU_TS'\n",
    "            version = '4.04'\n",
    "        elif var in ['pr', 'precip']:\n",
    "            obs_name = 'APHRO_MA'\n",
    "            version = 'V1101'\n",
    "        elif var in ['ta']:\n",
    "            obs_name = 'ERAI'\n",
    "            version = ''\n",
    "\n",
    "        obs = u.get_obs(obs_name, version, var, period=period, machine='CICLAD', regrid=clim_ref)\n",
    "        clim_obs = u.clim(\n",
    "            obs.sel(time=period, lat=latlim, lon=lonlim), season=season, calendar='standard')\n",
    "        \n",
    "        list_ref.append(ref)\n",
    "        list_new.append(new)\n",
    "        list_obs.append(obs)\n",
    "        list_clim_ref.append(clim_ref)\n",
    "        list_clim_new.append(clim_new)\n",
    "        list_clim_obs.append(clim_obs)\n",
    "               \n",
    "    return list_ref, list_new, list_obs, list_clim_ref, list_clim_new, list_clim_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot differences and compare to observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    #############\n",
      "    ### Variable: frac_snow \n",
      "    #############\n",
      "            \n",
      "Open reference simulation:\n",
      "/thredds/idris/work/ufz23bm/LMDZOR/DEVT/amip/LMDZORnudge-STD-NY07/SRF/Analyse/TS_MO/LMDZORnudge-STD-NY07_20040101_20131231_1M_frac_snow.nc\n",
      "\n",
      "Open new simulation:\n",
      "/thredds/idris/work/ufz23bm/LMDZOR/DEVT/amip/LMDZORnudge-STD-R01-opti/SRF/Analyse/TS_MO/LMDZORnudge-STD-R01-opti_20040101_20131231_1M_frac_snow.nc\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/thredds/idris/work/ufz23bm/LMDZOR/DEVT/amip/LMDZORnudge-STD-R01-opti/SRF/Analyse/TS_MO/LMDZORnudge-STD-R01-opti_20040101_20131231_1M_frac_snow.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/phd_v3/lib/python3.8/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phd_v3/lib/python3.8/site-packages/xarray/backends/lru_cache.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/thredds/idris/work/ufz23bm/LMDZOR/DEVT/amip/LMDZORnudge-STD-R01-opti/SRF/Analyse/TS_MO/LMDZORnudge-STD-R01-opti_20040101_20131231_1M_frac_snow.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1b09379c6325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mzone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'HMA'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m list_ref, list_new, list_obs, list_clim_ref, list_clim_new, list_clim_obs = get_data(\n\u001b[0m\u001b[1;32m     10\u001b[0m     list_vars, period, season, zone)\n",
      "\u001b[0;32m<ipython-input-4-87755a7379cd>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(list_vars, period, season, zone)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mexp_new\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/Analyse/TS_MO/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mexp_new\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_20040101_20131231_1M_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.nc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Open new simulation:\\n'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phd_v3/lib/python3.8/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables, backend_kwargs, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_remote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"netcdf4\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             store = backends.NetCDF4DataStore.open(\n\u001b[0m\u001b[1;32m    509\u001b[0m                 \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbackend_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/phd_v3/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         )\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phd_v3/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_remote_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phd_v3/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_store_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phd_v3/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nc4_require_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phd_v3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phd_v3/lib/python3.8/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36macquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;34m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_with_cache_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/phd_v3/lib/python3.8/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;31m# ensure file doesn't get overriden when opened again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/thredds/idris/work/ufz23bm/LMDZOR/DEVT/amip/LMDZORnudge-STD-R01-opti/SRF/Analyse/TS_MO/LMDZORnudge-STD-R01-opti_20040101_20131231_1M_frac_snow.nc'"
     ]
    }
   ],
   "source": [
    "# list_vars = ['frac_snow']\n",
    "list_vars = ['frac_snow', 't2m', 'precip']\n",
    "\n",
    "# Period for climatologies (removing first year spin-up)\n",
    "period = slice('2005','2013')\n",
    "season = 'annual'\n",
    "zone = 'HMA'\n",
    "\n",
    "list_ref, list_new, list_obs, list_clim_ref, list_clim_new, list_clim_obs = get_data(\n",
    "    list_vars, period, season, zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, var in enumerate(list_vars):\n",
    "    label, units, \\\n",
    "    levels, cmap, extend, \\\n",
    "    levels_diff, cmap_diff, extend_diff, \\\n",
    "    levels_bias, cmap_bias, extend_bias = u.get_var_infos(var)\n",
    "\n",
    "    u.plot_ref_new_obs(\n",
    "        var, list_clim_ref[i], list_clim_new[i], list_clim_obs[i], label, units,\n",
    "        levels, cmap, extend,\n",
    "        levels_diff, cmap_diff, extend_diff,\n",
    "        levels_bias, cmap_bias, extend_bias,\n",
    "        save=False, dpi=300\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Northern Hemisphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_vars = ['frac_snow']\n",
    "list_vars = ['frac_snow', 't2m']\n",
    "\n",
    "# Period for climatologies (removing first year spin-up)\n",
    "period = slice('2005','2013')\n",
    "season = 'annual'\n",
    "zone = 'NH'\n",
    "\n",
    "list_ref, list_new, list_obs, list_clim_ref, list_clim_new, list_clim_obs = get_data(\n",
    "    list_vars, period, season, zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, var in enumerate(list_vars):\n",
    "    label, units, \\\n",
    "    levels, cmap, extend, \\\n",
    "    levels_diff, cmap_diff, extend_diff, \\\n",
    "    levels_bias, cmap_bias, extend_bias = u.get_var_infos(var)\n",
    "\n",
    "    u.plot_ref_new_obs(\n",
    "        var, list_clim_ref[i], list_clim_new[i], list_clim_obs[i], label, units,\n",
    "        levels, cmap, extend,\n",
    "        levels_diff, cmap_diff, extend_diff,\n",
    "        levels_bias, cmap_bias, extend_bias,\n",
    "        save=False, dpi=300\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World topography\n",
    "https://www.ngdc.noaa.gov/mgg/image/color_etopo1_ice_low.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/color_etopo1_ice_low.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zonal plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vars = ['ta']\n",
    "\n",
    "# Period for climatologies (removing first year spin-up)\n",
    "period = slice('2005','2013')\n",
    "season = 'annual'\n",
    "zone = 'GLOB'\n",
    "\n",
    "list_ref, list_new, list_obs, list_clim_ref, list_clim_new, list_clim_obs = get_data(\n",
    "    list_vars, period, season, zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_vars)):\n",
    "    list_clim_ref[i].load()\n",
    "    list_clim_new[i].load()\n",
    "    list_clim_obs[i].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, var in enumerate(list_vars):\n",
    "    label, units, \\\n",
    "    levels, cmap, extend, \\\n",
    "    levels_diff, cmap_diff, extend_diff, \\\n",
    "    levels_bias, cmap_bias, extend_bias = u.get_var_infos(var)\n",
    "\n",
    "    u.plot_zonal_bias_HMA(\n",
    "        var, list_clim_ref[i], list_clim_new[i], list_clim_obs[i], label, units,\n",
    "        levels_diff, cmap_diff, extend_diff,\n",
    "        levels_bias, cmap_bias, extend_bias,\n",
    "        save=False, dpi=300\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWE/SCE\n",
    "\n",
    "Il faut récupérer les variables liées à la neige dans le TimeSeries !\n",
    "- snow\n",
    "- snowage\n",
    "- snownobio\n",
    "- snownobioage\n",
    "- snowmelt\n",
    "- snowmelt_from_maxmass\n",
    "- pkappa_snow\n",
    "- pcapa_snow\n",
    "- snowtemp\n",
    "- snowtemp_weighted\n",
    "- snowliq\n",
    "- snowdz\n",
    "- snowrho\n",
    "- snowheat\n",
    "- snowgrain\n",
    "- **snowdepth**\n",
    "- frac_snow\n",
    "- snowliqtot\n",
    "- snowage_glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /thredds/idris/work/ufz23bm/IGCM_OUT/LMDZOR/PROD/clim/LMDZOR-STD-REF/SRF/Analyse/TS_MO/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'frac_snow'\n",
    "component = 'SRF'\n",
    "\n",
    "path = root+exp_ref+'/'+component+'/Analyse/TS_MO/'+exp_ref+'_20040101_20131231_1M_'+var+'.nc'\n",
    "print('Open reference simulation:\\n'+path+'\\n')\n",
    "frac_snow_ref = xr.open_dataset(path)[var]\n",
    "frac_snow_ref.attrs['title'] = exp_ref\n",
    "\n",
    "path = root+exp_new+'/'+component+'/Analyse/TS_MO/'+exp_new+'_20040101_20131231_1M_'+var+'.nc'\n",
    "print('Open new simulation:\\n'+path+'\\n')\n",
    "frac_snow_new = xr.open_dataset(path)[var]\n",
    "frac_snow_new.attrs['title'] = exp_new\n",
    "\n",
    "# Rename time dimension and sort latitude from -90 to 90\n",
    "frac_snow_ref = frac_snow_ref.rename({'time_counter': 'time'}).sortby('lat')\n",
    "frac_snow_new = frac_snow_new.rename({'time_counter': 'time'}).sortby('lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'snow'\n",
    "path = root+exp_ref+'/'+component+'/Analyse/TS_MO/'+exp_ref+'_20040101_20131231_1M_'+var+'.nc'\n",
    "print('Open reference simulation:\\n'+path+'\\n')\n",
    "snow_ref = xr.open_dataset(path)[var]\n",
    "snow_ref.attrs['title'] = exp_ref\n",
    "\n",
    "path = root+exp_new+'/'+component+'/Analyse/TS_MO/'+exp_new+'_20040101_20131231_1M_'+var+'.nc'\n",
    "print('Open new simulation:\\n'+path+'\\n')\n",
    "snow_new = xr.open_dataset(path)[var]\n",
    "snow_new.attrs['title'] = exp_new\n",
    "\n",
    "# Rename time dimension and sort latitude from -90 to 90\n",
    "snow_ref = snow_ref.rename({'time_counter': 'time'}).sortby('lat')\n",
    "snow_new = snow_new.rename({'time_counter': 'time'}).sortby('lat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get STD of topography\n",
    "path_grid = '/thredds/idris/work/ufz23bm/IGCM_OUT/LMDZ/ELC-144x142x79-GMTED-STD/ATM/Output/Grid/'\n",
    "grid = xr.open_dataset(path_grid+'ELC-144x142x79-GMTED-STD_grilles_gcm.nc')\n",
    "\n",
    "path_restart = '/thredds/idris/work/ufz23bm/IGCM_OUT/LMDZ/ELC-144x142x79-GMTED-STD/ATM/Output/Restart/'\n",
    "startphy = xr.open_dataset(path_restart+'ELC-144x142x79-GMTED-STD_clim_startphy.nc')\n",
    "std = u.phys2dyn(startphy.ZSTD_NOT_FILTERED, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select domain and period\n",
    "zone = 'HMA'\n",
    "latlim, lonlim = u.get_zone(zone)\n",
    "period = slice('2005','2013')\n",
    "\n",
    "frac_snow_ref = frac_snow_ref.sel(time=period, lat=latlim, lon=lonlim)\n",
    "frac_snow_new = frac_snow_new.sel(time=period, lat=latlim, lon=lonlim)\n",
    "snow_ref = snow_ref.sel(time=period, lat=latlim, lon=lonlim)\n",
    "snow_new = snow_new.sel(time=period, lat=latlim, lon=lonlim)\n",
    "\n",
    "std = std.sel(lat=latlim, lon=lonlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(nrows=3, ncols=4, axwidth=2)\n",
    "\n",
    "xylim = [[0, 500], [0, 100]]\n",
    "bins = 100\n",
    "cmap = 'Spectral_r'\n",
    "norm = 'log'\n",
    "vmin=1\n",
    "cmin=1\n",
    "\n",
    "\n",
    "k = 0\n",
    "# All points\n",
    "for month in range(2,6):\n",
    "    m = axs[k].hist2d(\n",
    "        snow_ref.where(snow_ref['time.month'] == month, drop=True).values.flatten(), \n",
    "        frac_snow_ref.where(snow_ref['time.month'] == month, drop=True).values.flatten(), \n",
    "        bins=bins, range=xylim, cmap=cmap, norm=norm, vmin=vmin, cmin=cmin\n",
    "    )\n",
    "    k += 1\n",
    "\n",
    "# STD < 200\n",
    "for month in range(2,6):\n",
    "    m = axs[k].hist2d(\n",
    "        snow_ref.where(\n",
    "            (snow_ref['time.month'] == month) & (std < 200),\n",
    "             drop=True\n",
    "        ).values.flatten(), \n",
    "        frac_snow_ref.where(snow_ref['time.month'] == month, drop=True).values.flatten(), \n",
    "        bins=bins, range=xylim, cmap=cmap, norm=norm, vmin=vmin, cmin=cmin\n",
    "    )\n",
    "    k += 1\n",
    "\n",
    "# STD > 200\n",
    "for month in range(2,6):\n",
    "    m = axs[k].hist2d(\n",
    "        snow_ref.where(\n",
    "            (snow_ref['time.month'] == month) & (std > 200),\n",
    "             drop=True\n",
    "        ).values.flatten(), \n",
    "        frac_snow_ref.where(snow_ref['time.month'] == month, drop=True).values.flatten(), \n",
    "        bins=bins, range=xylim, cmap=cmap, norm=norm, vmin=vmin, cmin=cmin\n",
    "    )\n",
    "    k += 1\n",
    "\n",
    "axs.format(\n",
    "    collabels=['Feb', 'Mar', 'Apr', 'May'],\n",
    "    rowlabels=['All points', 'STD < 200', 'STD > 200'],\n",
    "    xlabel=snow_ref.long_name + ' [' + snow_ref.units + ']',\n",
    "    ylabel='Snow Cover Extent [' + frac_snow_ref.units + ']',\n",
    "    suptitle=snow_ref.attrs['title'] + ' (' + period.start + '-' + period.stop + ')'\n",
    ")\n",
    "\n",
    "# for extension in ['jpg', 'png', 'pdf']:\n",
    "#     fig.save(\n",
    "#         'img/SCE-SWE_' +\n",
    "#         zone +\n",
    "#         '_Feb-May_' +\n",
    "#         period.start + '-' + period.stop +\n",
    "#         '_' +\n",
    "#         snow_ref.attrs['title'] +\n",
    "#         '.' +\n",
    "#         extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(nrows=3, ncols=4, axwidth=2)\n",
    "\n",
    "xylim = [[0, 500], [0, 100]]\n",
    "bins = 100\n",
    "cmap = 'Spectral_r'\n",
    "norm = 'log'\n",
    "vmin=1\n",
    "cmin=1\n",
    "\n",
    "\n",
    "k = 0\n",
    "# All points\n",
    "for month in range(2,6):\n",
    "    m = axs[k].hist2d(\n",
    "        snow_new.where(snow_new['time.month'] == month, drop=True).values.flatten(), \n",
    "        frac_snow_new.where(snow_new['time.month'] == month, drop=True).values.flatten(), \n",
    "        bins=bins, range=xylim, cmap=cmap, norm=norm, vmin=vmin, cmin=cmin\n",
    "    )\n",
    "    k += 1\n",
    "\n",
    "# STD < 200\n",
    "for month in range(2,6):\n",
    "    m = axs[k].hist2d(\n",
    "        snow_new.where(\n",
    "            (snow_new['time.month'] == month) & (std < 200),\n",
    "             drop=True\n",
    "        ).values.flatten(), \n",
    "        frac_snow_new.where(snow_new['time.month'] == month, drop=True).values.flatten(), \n",
    "        bins=bins, range=xylim, cmap=cmap, norm=norm, vmin=vmin, cmin=cmin\n",
    "    )\n",
    "    k += 1\n",
    "\n",
    "# STD > 200\n",
    "for month in range(2,6):\n",
    "    m = axs[k].hist2d(\n",
    "        snow_new.where(\n",
    "            (snow_new['time.month'] == month) & (std > 200),\n",
    "             drop=True\n",
    "        ).values.flatten(), \n",
    "        frac_snow_new.where(snow_new['time.month'] == month, drop=True).values.flatten(), \n",
    "        bins=bins, range=xylim, cmap=cmap, norm=norm, vmin=vmin, cmin=cmin\n",
    "    )\n",
    "    k += 1\n",
    "\n",
    "axs.format(\n",
    "    collabels=['Feb', 'Mar', 'Apr', 'May'],\n",
    "    rowlabels=['All points', 'STD < 200', 'STD > 200'],\n",
    "    xlabel=snow_new.long_name + ' [' + snow_new.units + ']',\n",
    "    ylabel='Snow Cover Extent [' + frac_snow_new.units + ']',\n",
    "    suptitle=snow_new.attrs['title'] + ' (' + period.start + '-' + period.stop + ')'\n",
    ")\n",
    "\n",
    "# for extension in ['jpg', 'png', 'pdf']:\n",
    "#     fig.save(\n",
    "#         'img/SCE-SWE_' +\n",
    "#         zone +\n",
    "#         '_Feb-May_' +\n",
    "#         period.start + '-' + period.stop +\n",
    "#         '_' +\n",
    "#         snow_new.attrs['title'] +\n",
    "#         '.' +\n",
    "#         extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-phd_v3] *",
   "language": "python",
   "name": "conda-env-.conda-phd_v3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
